{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress Warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import common GIS tools\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio.features\n",
    "import rioxarray as rio\n",
    "import xrspatial.multispectral as ms\n",
    "import pandas as pd\n",
    "# Import Planetary Computer tools\n",
    "import pystac_client\n",
    "import planetary_computer as pc\n",
    "import odc\n",
    "from odc.stac import stac_load\n",
    "from odc.algo import to_rgba\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read_csv\n",
    "df = pd.read_csv('challenge_1_submission_template_correct_columns_fixed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_longs = list(df['id'].apply(lambda x: x[1:-1]))\n",
    "#lat_longs = list(df['id'].apply(lambda x: x[1:-1]))\n",
    "box_size_deg = 0.05\n",
    "time_window=\"2021-11-01/2022-08-31\"\n",
    "stac = pystac_client.Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pixel resolution for the final product\n",
    "# Define the scale according to our selected crs, so we will use degrees\n",
    "resolution =  10 # meters per pixel \n",
    "scale = resolution / 111320.0 # degrees per pixel for CRS:4326 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To mask the pixels and find clouds or water, it is best to use the bit values of the 16-bit qa_pixel flag\n",
    "# See the website above for a nice explanation of the process\n",
    "\n",
    "bit_flags = {\n",
    "            'fill': 1<<0,\n",
    "            'dilated_cloud': 1<<1,\n",
    "            'cirrus': 1<<2, \n",
    "            'cloud': 1<<3,\n",
    "            'shadow': 1<<4, \n",
    "            'snow': 1<<5, \n",
    "            'clear': 1<<6,\n",
    "            'water': 1<<7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that will mask pixels with a given type\n",
    "\n",
    "def get_mask(mask, flags_list):\n",
    "    \n",
    "    # Create the result mask filled with zeros and the same shape as the mask\n",
    "    final_mask = np.zeros_like(mask)\n",
    "    \n",
    "    # Loop through the flags  \n",
    "    for flag in flags_list:\n",
    "        \n",
    "        # get the mask for each flag\n",
    "        flag_mask = np.bitwise_and(mask, bit_flags[flag])\n",
    "        \n",
    "        # add it to the final flag\n",
    "        final_mask = final_mask | flag_mask\n",
    "    \n",
    "    return final_mask > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "#define column\n",
    "Latitude_Longtitudes = list()\n",
    "time_frames = list()\n",
    "original_red = list()\n",
    "original_blue= list()\n",
    "original_green = list()\n",
    "original_ndvi = list()\n",
    "\n",
    "filter_red = list()\n",
    "filter_blue= list()\n",
    "filter_green = list()\n",
    "filter_ndvi = list()\n",
    "\n",
    "filter_lir = list()\n",
    "filter_swir= list()\n",
    "original_lir= list()\n",
    "original_swir = list()\n",
    "\n",
    "original_nir = list()\n",
    "filter_nir= list()\n",
    "original_savi= list()\n",
    "filter_savi= list()\n",
    "original_arvi = list()\n",
    "filter_arvi= list()\n",
    "original_evi = list()\n",
    "filter_evi= list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [56:13<00:00, 33.74s/it] \n"
     ]
    }
   ],
   "source": [
    "for lat_long in tqdm(lat_longs[:100]):\n",
    "    lat_long = tuple(map(float, lat_long.split(', ')))\n",
    "    min_lon = lat_long[1]-box_size_deg/2\n",
    "    min_lat = lat_long[0]-box_size_deg/2\n",
    "    max_lon = lat_long[1]+box_size_deg/2\n",
    "    max_lat = lat_long[0]+box_size_deg/2\n",
    "    bounds = (min_lon, min_lat, max_lon, max_lat)\n",
    "    \n",
    "    search = stac.search(\n",
    "    collections=[\"landsat-c2-l2\"],  #Landsat Collection 2 Level-2  #https://planetarycomputer.microsoft.com/dataset/group/landsat\n",
    "    bbox=bounds, \n",
    "    datetime=time_window,\n",
    "    query={\"platform\": {\"in\": [\"landsat-8\", \"landsat-9\"]},},\n",
    "    )\n",
    "    \n",
    "    items = search.get_all_items()\n",
    "    \n",
    "    # https://odc-stac.readthedocs.io/en/latest/notebooks/stac-load-S2-ms.html#Configuration\n",
    "    xx = stac_load(\n",
    "    items,\n",
    "    #bands=[\"red\", \"green\", \"blue\", \"nir08\", \"qa_pixel\"],  \n",
    "    bands=[\"red\", \"green\", \"blue\", \"nir08\", \"qa_pixel\", \"swir16\", \"lwir11\"],  \n",
    "            #bands to calculate nvdi: \"red\", \"nir08\"\n",
    "            #bands for adjust brightness of images: \"red\", \"green\", \"blue\"\n",
    "            #bands for filtering mask:  \"qa_pixel\", \"qa_radsat\", \"qa_aerosol\"\n",
    "    crs=\"EPSG:4326\", # Latitude-Longitude\n",
    "    resolution=scale, # Degrees\n",
    "    chunks={\"x\": 2048, \"y\": 2048},\n",
    "    patch_url=pc.sign,\n",
    "    bbox=bounds\n",
    "    )\n",
    "    \n",
    "    # Apply scaling and offsets for Landsat Collection-2 (reference below) to the spectral bands ONLY\n",
    "    # https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2\n",
    "    xx['red'] = (xx['red']*0.0000275)-0.2\n",
    "    xx['green'] = (xx['green']*0.0000275)-0.2\n",
    "    xx['blue'] = (xx['blue']*0.0000275)-0.2\n",
    "    xx['nir08'] = (xx['nir08']*0.0000275)-0.2\n",
    "    \n",
    "    if (len(xx.time) == 59) or (len(xx.time) == 58) or (len(xx.time) == 57):\n",
    "        xx = xx.drop_isel(time=[len(xx.time) - 10])\n",
    "    if len(xx.time) == 31:\n",
    "        xx = xx.drop_isel(time=[25])\n",
    "    if (len(xx.time) == 63) or (len(xx.time) == 64) or (len(xx.time) == 65):\n",
    "        xx = xx.drop_isel(time=[50,51,52])\n",
    "    if len(xx.time) == 91:\n",
    "        xx = xx.drop_isel(time=[74,75])\n",
    "    if (len(xx.time) == 66) or (len(xx.time) == 67):\n",
    "        xx = xx.drop_isel(time=[53,54])\n",
    "        \n",
    "    full_mask = get_mask(xx['qa_pixel'], ['fill', 'dilated_cloud', 'cirrus', 'cloud', 'shadow', 'water'])\n",
    "    cleaned_data = xx.where(~full_mask)\n",
    "    \n",
    "    # Calculate the mean of the data across the sample region and then NDVI\n",
    "    # Perform this calculation for the unfiltered and cloud-filtered (clean) datasets\n",
    "    time_frame = xx.time.values\n",
    "    \n",
    "    mean_unfiltered = xx.mean(dim=['longitude','latitude']).compute()\n",
    "    mean_red = mean_unfiltered.red.values\n",
    "    mean_blue = mean_unfiltered.blue.values\n",
    "    mean_green = mean_unfiltered.green.values\n",
    "    mean_nir = mean_unfiltered.nir08.values\n",
    "    ndvi_mean = ((mean_unfiltered.nir08-mean_unfiltered.red)/(mean_unfiltered.nir08+mean_unfiltered.red)).values\n",
    "    mean_swir = mean_unfiltered.swir16.values\n",
    "    mean_lwir = mean_unfiltered.lwir11.values\n",
    "    # mean_savi = ((mean_unfiltered.nir08 - mean_unfiltered.red)/(mean_unfiltered.nir08+mean_unfiltered.red +0.5)) * (1 + 0.5).values\n",
    "    # mean_arvi = (mean_unfiltered.nir08 - (mean_unfiltered.red -1*(mean_unfiltered.blue - mean_unfiltered.red)))/(mean_unfiltered.nir08 + (mean_unfiltered.red -(mean_unfiltered.blue - mean_unfiltered.red))).values\n",
    "    # mean_evi = 2.5*((mean_unfiltered.nir08 - mean_unfiltered.red)/((mean_unfiltered.nir08 + 6*mean_unfiltered.red -7.5*mean_unfiltered.blue)+1)).values\n",
    "   \n",
    "    mean_clean = cleaned_data.mean(dim=['longitude','latitude']).compute()\n",
    "    mean_red_clean = mean_clean.red.values\n",
    "    mean_blue_clean = mean_clean.blue.values\n",
    "    mean_green_clean = mean_clean.green.values\n",
    "    mean_nir_clean = mean_clean.nir08.values\n",
    "    ndvi_mean_clean = ((mean_clean.nir08-mean_clean.red)/(mean_clean.nir08+mean_clean.red)).values\n",
    "    mean_swir_clean = mean_clean.swir16.values\n",
    "    mean_lwir_clean = mean_clean.lwir11.values\n",
    "    # mean_savi_clean = ((mean_clean.nir08 - mean_clean.red)/(mean_clean.nir08+mean_clean.red +0.5)) * (1 + 0.5).values\n",
    "    # mean_arvi_clean = (mean_clean.nir08 - (mean_clean.red -1*(mean_clean.blue - mean_clean.red)))/(mean_clean.nir08 + (mean_clean.red - (mean_clean.blue - mean_clean.red))).values\n",
    "    # mean_evi_clean = 2.5*((mean_clean.nir08 - mean_clean.red)/((mean_clean.nir08 + 6*mean_clean.red -7.5*mean_clean.blue)+1)).values\n",
    "\n",
    "    \n",
    "    Latitude_Longtitudes.extend([lat_long]*len(time_frame))\n",
    "    time_frames.extend(time_frame)\n",
    "    original_red.extend(mean_red)\n",
    "    original_blue.extend(mean_blue)\n",
    "    original_green.extend(mean_green)\n",
    "    original_ndvi.extend(ndvi_mean)\n",
    "    original_lir.extend(mean_lwir)\n",
    "    original_swir.extend(mean_swir)\n",
    "    original_nir.extend(mean_nir)\n",
    "    # original_savi.extend(mean_savi)\n",
    "    # original_arvi.extend(mean_arvi)\n",
    "    # original_evi.extend(mean_evi)\n",
    "    \n",
    "    \n",
    "    \n",
    "    filter_red.extend(mean_red_clean)\n",
    "    filter_blue.extend(mean_blue_clean)\n",
    "    filter_green.extend(mean_green_clean)\n",
    "    filter_ndvi.extend(ndvi_mean_clean)\n",
    "    filter_lir.extend(mean_lwir_clean)\n",
    "    filter_swir.extend(mean_swir_clean)\n",
    "    filter_nir.extend(mean_nir_clean)\n",
    "    # filter_savi.extend(mean_savi_clean)\n",
    "    # filter_arvi.extend(mean_arvi_clean)\n",
    "    # filter_evi.extend(mean_evi_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame({'Latitude_Longtitudes': Latitude_Longtitudes,\n",
    "        'time_frames': time_frames,\n",
    "        'original_red':original_red,\n",
    "        'original_blue':original_blue,\n",
    "        'original_green': original_green,\n",
    "        'original_ndvi' :original_ndvi,\n",
    "        'filter_red':filter_red,\n",
    "        'filter_blue':filter_blue,\n",
    "        'filter_green':filter_green ,\n",
    "        'filter_ndvi': filter_ndvi,\n",
    "        'filter_lir': filter_lir,\n",
    "        'original_lir': original_lir,\n",
    "        'original_swir': original_swir,\n",
    "        'filter_swir': filter_swir,\n",
    "        'original_nir': original_nir,\n",
    "        'filter_nir': filter_nir})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['time_frames'] = df_new['time_frames'].dt.strftime('%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['original_savi'] = ((df_new['original_nir'] - df_new['original_red'])/(df_new['original_nir']+df_new['original_red'] +0.5)) * (1 + 0.5)\n",
    "df_new['filter_savi'] = ((df_new['filter_nir'] - df_new['filter_red'])/(df_new['filter_nir']+df_new['filter_red'] +0.5)) * (1 + 0.5)\n",
    "df_new['original_arvi'] = (df_new['original_nir'] - (df_new['original_red'] -1*(df_new['original_blue'] - df_new['original_red'])))/(df_new['original_nir'] + (df_new['original_red'] -(df_new['original_blue'] - df_new['original_red'])))\n",
    "df_new['filter_arvi'] = (df_new['filter_nir'] - (df_new['filter_red'] -1*(df_new['filter_blue'] - df_new['filter_red'])))/(df_new['filter_nir'] + (df_new['filter_red'] -(df_new['filter_blue'] - df_new['filter_red'])))\n",
    "\n",
    "df_new['original_evi'] = 2.5*((df_new['original_nir'] - df_new['original_red'])/((df_new['original_nir'] + 6*df_new['original_red'] -7.5*df_new['original_blue'])+1))\n",
    "df_new['filter_evi'] = 2.5*((df_new['filter_nir'] - df_new['filter_red'])/((df_new['filter_nir'] + 6*df_new['filter_red'] -7.5*df_new['filter_blue'])+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv(\"train-landsat.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2ca0804b9f904dab815db80637a4f2d9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e2f3ac516e3b4cf3a1ba1fc6aa0897ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "layout": "IPY_MODEL_2ca0804b9f904dab815db80637a4f2d9"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
